{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346ad4d-2b70-4eec-a60b-3298ea4ae0ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install transformers torch pandas numpy kagglehub hf_transfer scikit-learn matplotlib rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e31915-4e1e-493b-98aa-7bd718324a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe112d1-8aa2-45d8-9960-2e633539f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/andrewmvd/cyberbullying-classification?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.82M/2.82M [00:00<00:00, 4.17MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/andrewmvd/cyberbullying-classification/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"andrewmvd/cyberbullying-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b602a4f-19f0-49a9-b076-a4629c60f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb3a84-f733-4e6e-bdf2-21cec34348f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared GPU cache ✅\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, gc\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.console import Console\n",
    "from rich.progress import Progress, BarColumn, TimeElapsedColumn, TimeRemainingColumn, TextColumn\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.amp import autocast, GradScaler\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.optim.lr_scheduler\")\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "console = Console()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Cleared GPU cache ✅\")\n",
    "\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "path = '/root/.cache/kagglehub/datasets/andrewmvd/cyberbullying-classification/versions/1/cyberbullying_tweets.csv'\n",
    "df = pd.read_csv(path, sep=',')\n",
    "\n",
    "\n",
    "# Map each label as an integer\n",
    "label_map = {\n",
    "    'not_cyberbullying' : 0,\n",
    "    'gender' : 1,\n",
    "    'religion' : 2,\n",
    "    'other_cyberbullying' : 3,\n",
    "    'age' : 4,\n",
    "    'ethnicity' : 5\n",
    "}\n",
    "\n",
    "df[\"label\"] = df[\"cyberbullying_type\"].map(label_map)\n",
    "\n",
    "num_labels=df['label'].nunique()\n",
    "\n",
    "\n",
    "def preprocess(tweet):\n",
    "    return tokenizer(tweet, truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-large-uncased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoded_tweets = df['tweet_text'].apply(preprocess)\n",
    "\n",
    "df[\"input_ids\"] = encoded_tweets.apply(lambda x: x[\"input_ids\"])\n",
    "df[\"attention_mask\"] = encoded_tweets.apply(lambda x: x[\"attention_mask\"])\n",
    "\n",
    "# Convert to tensors\n",
    "inputs = torch.tensor(df[\"input_ids\"].tolist())\n",
    "masks = torch.tensor(df[\"attention_mask\"].tolist())\n",
    "labels = torch.tensor(df[\"label\"].tolist())\n",
    "\n",
    "dataset = TensorDataset(inputs, masks, labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5673d-957a-4688-b30f-2641215e71d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Focal Loss method\n",
    "def focal_loss(inputs, targets, gamma=2.0):\n",
    "    ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    loss = (1 - pt) ** gamma ** ce_loss\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "\n",
    "# Train model\n",
    "def train_model(num_epochs, scheduler):\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss=0\n",
    "        console.rule(f\"[bold green]Epoch {epoch+1}/{num_epochs}\", align='center')\n",
    "        with Progress(\n",
    "            TextColumn(\"[bold dodger_blue1]{task.description}\"),\n",
    "            BarColumn(),\n",
    "            TextColumn(\"[bold dodger_blue1]{task.percentage:>3.1f}%[/bold dodger_blue1]\"),\n",
    "            \"•\",\n",
    "            TimeElapsedColumn(),\n",
    "            \"•\",\n",
    "            TimeRemainingColumn(),\n",
    "            console=console,\n",
    "            transient=True,\n",
    "        ) as progress:\n",
    "            task = progress.add_task(\"Training\", total=len(train_loader))\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                batch = [x.to(device) for x in batch]\n",
    "                optimizer.zero_grad()\n",
    "                with autocast(device_type=\"cuda\", dtype=torch.bfloat16): \n",
    "                    input_ids, attention_mask, labels = batch\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        labels=labels\n",
    "                        )\n",
    "                    loss = focal_loss(outputs.logits, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "                progress.advance(task)\n",
    "                progress.update(task, description=f\"Training (loss={loss.item():.4f})\")\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        console.print(f'[orchid1]Epoch {epoch+1} completed | Average loss: [bold bright_yellow]{avg_loss:.4f}[/bold bright_yellow]\\n')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "def eval_model(model):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = [x.to(device) for x in batch]\n",
    "            input_ids, attention_mask, labels = batch \n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            \n",
    "            \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_labels)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "    print(\"\\nDetailed report:\\n\", classification_report(all_labels, all_preds))\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505f9fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    epochs = 10\n",
    "    best_lr = 3e-5\n",
    "    num_training_steps = len(train_loader) * epochs\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-large-uncased\", num_labels=num_labels).to(device)\n",
    "\n",
    "    for param in model.bert.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "    for layer in model.bert.encoder.layer[:8]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=best_lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=int(0.1 * num_training_steps),\n",
    "                num_training_steps=num_training_steps\n",
    "            )\n",
    "\n",
    "    trained_model = train_model(epochs, scheduler)\n",
    "\n",
    "    acc, f1 = eval_model(trained_model)\n",
    "\n",
    "    print(f\"\\nAccuracy: {acc}\")\n",
    "    print(f\"\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7257fcb-b2f5-4cac-994d-b87c55ae23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save_pretrained('bert_cyberbullying_model')\n",
    "tokenizer.save_pretrained('bert_cyberbullying_model')\n",
    "\n",
    "import os\n",
    "os.listdir('bert_cyberbullying_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
